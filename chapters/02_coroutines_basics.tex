% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.



% • Describing different methods
% • Indicating a specific method
% • Giving reasons why a particular method was adopted
% • Indicating sample size and characteristics
% • Indicating reasons for sample characteristics
% • Describing the process: Indicating problems or limitations


%%% ====== COROUTINES BASICS =======================
\chapter{Coroutines and Cache Misses Fundamentals}\label{chapter:CacheCoroDSFundamentals}

%%% ====== COROUTINES =======================
\section{C++ Coroutines}
% \section{C++ Coroutines Coroutine CPP Reference standardisation history}\label{section:Coroutines}
% Citation test~\parencite{latex}.

%%% ------- Intro to COROUTINES ------------------------
\subsection{Introduction to Coroutines}
C++ Coroutines are available in the std namespace from the C++20 standard on, and from the C++23 standard there is a generator implementation based on the C++ 20 coroutine concept.
% https://en.cppreference.com/w/cpp/language/coroutines

A coroutine is a generalization of a function, being able additionally to normal functions to suspended execution and resumed it later on.
Any function is a coroutine if its definition contains at least one of these three keywords:
\begin{itemize}
  \item co\_await - to suspend execution
  \item co\_yield - to suspend execution and returning a value
  \item co\_return - to complete exeuction and returning a value
\end{itemize}
C++ Coroutines are stackless, meaning by suspension and consecutively returning to the caller, the data of the coroutine is stored separately from the stack, namely on the heap.
This allows sequential code to be executed asynchronously, without blocking the thread of execution and supports algorithms to be lazily computed, e.g. generators.
However, there are some restrictions to coroutines: They cannot use variadic arguments, plain return statements or placeholder return types likes auto or Concept.
Also consteval, conexpr and the main function as well as constructors and destructors cannot be coroutines.

To illustrate the difference between coroutines and functions, this paragraph provides a background and general information of function calls and return:
A normal function has a single entry point - the Call operation - and a single exit point - the Return operation.
The Call operation creates an activation frame, suspends execution of the caller and transfers execution to the callee, where the caller is the invocating function and the callee is the invocated function.
The Return operation returns the value in the return statement to the caller, destroys the activation frame and then resumes execution of the caller.
These operations include calling conventions splitting the responsibilites of the caller and callee regarding saving register values to their activation frames.
The activation frame is also commonly called stack frame, as the functions state (parameters, local variables) are stored on the stack.
Normal Functions have strictly nested lifetimes, meaning they run synchronously from start to finish, allowing the stack to be a highly efficient memory allocation data-structure for allocation and freeing frames.
The pointer pointing at the top of the stack is the **rsp** register on X86-64 CPU Architectures.

Coroutines have, additionally to the call and return operation, three extra operations, namely suspend, resume and destroy.
As coroutines can suspend execution without destroying the activation frame, as it may be resumed later, the activation frames are not strictly nested anymore.
This requires that after the creation of the coroutine on the stack, the state of the coroutine is saved to the heap,
like illustrated in \autoref{fig:CallingACoroutineHeap} where a normal function f() calls a coroutine function c().
% https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4680.pdf

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\paperwidth]{figures/coroutines_drawing2_coro_call_heap.png}
  \caption{Calling a Coroutine - Heap Allocation}
  % \quelle{\cite{ADaSurvey}}
  \label{fig:CallingACoroutineHeap}
\end{figure}

If the coroutine calls another normal function g(), g() 's activation frame is created on the stack and the coroutine stack frame points to the heap allocated frame,
 as illustrated in \autoref{fig:CoroutineCallsNormalFunction}. When g() returns, it destroys its activation frame and restores c()'s activation frame.
\begin{figure}[h]
  \begin{minipage}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/coroutines_drawing3_coro_calls_other_func.png}
    \caption{Coroutine calling a normal Function g()}
    \label{fig:CoroutineCallsNormalFunction}
  \end{minipage}
  \hfill
  \begin{minipage}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/coroutines_drawing4_other_func_returns.png}
    \caption{Normal Function g() returns}
    \label{fig:NormalFunctionReturns}
  \end{minipage}
\end{figure}

If c() now hits a supension point as shown in \autoref{fig:CoroSuspensionPoint}, the Suspend operation is invoked where c() suspends execution and returns control to f() without destroying its activation frame.
The Suspend operation interrupts execution of the coroutine at a current, well-defined point - co\_await or co\_yield -, within the function and potentially transfers execution back to the caller without destroying the activation frame.

This results in the stack-frame part of c() being popped off the stack while leaving the coroutine-frame on the heap.
When the coroutine suspends for the first time, a return-value is returned to the caller.
This return value often holds a handle to the coroutine-frame that suspended that can be used to later resume it.
When c() suspends it also stores the address of the resumption-point of c() in the coroutine frame (in the illustration called RP for resume-point).

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\paperwidth]{figures/coroutines_drawing5_coro_suspension_point.png}
  \caption{Coroutine hits Suspension Point}
  % \quelle{\cite{ADaSurvey}}
  \label{fig:CoroSuspensionPoint}
\end{figure}

The Resume operation transfers execution back to the coroutine at the point it was suspended whereas the Destroy operation is the only operation that destroys the activation frame of the coroutine.

This handle may now be passed around as a normal value between functions. At some point later, potentially from a different call-stack or even on a different thread, something (say, h()) will decide to resume execution of that coroutine. For example, when an async I/O operation completes.

The function that resumes the coroutine calls a void resume(handle) function to resume execution of the coroutine. To the caller, this looks just like any other normal call to a void-returning function with a single argument.

This creates a new stack-frame that records the return-address of the caller to resume(), activates the coroutine-frame by loading its address into a register and resumes execution of x() at the resume-point stored in the coroutine-frame.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\paperwidth]{figures/coroutines_drawing6_resumption_of_coroutine.png}
  \caption{Resumption of a Coroutine}
  % \quelle{\cite{ADaSurvey}}
  \label{fig:CoroResumption}
\end{figure}

\cite{baker2017coroutines}


%%% ------- Execution of a Coroutine ------------------------
\subsection{Execution of a Coroutine}
% https://en.cppreference.com/w/cpp/language/coroutines.html, and lewis baker

Each coroutine is associated with a promise object, a coroutine handle and the coroutine state.
% the promise object, manipulated from inside the coroutine. The coroutine submits its result or exception through this object. Promise objects are in no way related to std::promise.
% the coroutine handle, manipulated from outside the coroutine. This is a non-owning handle used to resume execution of the coroutine or to destroy the coroutine frame.
% the coroutine state, which is internal, dynamically-allocated storage (unless the allocation is optimized out), object that contains
% - the promise object
% - the parameters (all copied by value)
% - some representation of the current suspension point, so that a resume knows where to continue, and a destroy knows what local variables were in scope
% - local variables and temporaries whose lifetime spans the current suspension point.

As partially illustrated in \autoref{fig:CallingACoroutineHeap}, when a coroutine begins execution, it performs the following:
- allocates the coroutine state object using operator new and copies all function parameters to the coroutine state.
- calls the constructor for the promise object.
- calls promise.get\_return\_object() and stores the result in a local variable, which will be returned to the caller on the first suspension point of the coroutine.
- calls promise.initial\_suspend() and co\_awaits its result. Typically returns std::suspend\_always (lazily-started) or std::suspend\_never (eagerly-started).
- when co\_await promise.initial\_suspend() resumes, starts executing the body of the coroutine.

\begin{lstlisting}[language=C, frame=single, caption={coroutine execution}, label={lst:coroutine_execution}]
{
  co_await promise.initial_suspend();
  try
  {
    <body-statements>
  }
  catch (...)
  {
    promise.unhandled_exception();
  }
FinalSuspend:
  co_await promise.final_suspend();
}
\end{lstlisting}


When a coroutine reaches a suspension point, co\_await or co\_yield, the return object obtained earlier is returned to the caller/resumer. %, after implicit conversion to the return type of the coroutine, if necessary.
When encountering the co\_return statement, it calls either promise.return\_void()
or promise.return\_value(expr) depending on whether an expression is provided and whether this expression is non-void.
Furthermore, all variable with automatic storage duration are destroyed in reverse order of their creation and finally calling promise.final\_suspend() and co\_awaiting its result.
When falling off the end of the coroutine, meaning there is no co\_return statement, it is equivalent to a co\_return; statement.

% Returning from the coroutine using co_return
% When the coroutine reaches a co_return statement, it is translated into either a call to promise.return_void() or promise.return_value(<expr>) followed by a goto FinalSuspend;.

% The rules for the translation are as follows:

% co_return;
% -> promise.return_void();
% co_return <expr>;
% -> <expr>; promise.return_void(); if <expr> has type void
% -> promise.return_value(<expr>); if <expr> does not have type void
% The subsequent goto FinalSuspend; causes all local variables with automatic storage duration to be destructed in reverse order of construction before then evaluating co_await promise.final_suspend();.

% Note that if execution runs off the end of a coroutine without a co_return statement then this is equivalent to having a co_return; at the end of the function body. In this case, if the promise_type does not have a return_void() method then the behaviour is undefined.

% If either the evaluation of <expr> or the call to promise.return_void() or promise.return_value() throws an exception then the exception still propagates to promise.unhandled_exception() (see below).





%% uncaught expression
% If the coroutine ends with an uncaught exception, it performs the following:
% catches the exception and calls promise.unhandled_exception() from within the catch-block
% calls promise.final_suspend() and co_awaits the result (e.g. to resume a continuation or publish a result). It's undefined behavior to resume a coroutine from this point.
% When the coroutine state is destroyed either because it terminated via co_return or uncaught exception, or because it was destroyed via its handle, it does the following:
% calls the destructor of the promise object.
% calls the destructors of the function parameter copies.
% calls operator delete to free the memory used by the coroutine state.
% transfers execution back to the caller/resumer.
%% \paragraph{Dynamic allocation}
% Coroutine state is allocated dynamically via non-array operator new.
% The call to operator new can be optimized out (even if custom allocator is used) if The lifetime of the coroutine state is strictly nested within the lifetime of the caller, and
% the size of coroutine frame is known at the call site. In that case, coroutine state is embedded in the caller's stack frame (if the caller is an ordinary function) or coroutine state (if the caller is a coroutine).
% If allocation fails, the coroutine throws std::bad\_alloc, unless the Promise type defines the member function Promise::get\_return\_object\_on\_allocation\_failure(). If that member function is defined, allocation uses the nothrow form of operator new and on allocation failure, the coroutine immediately returns the object obtained from Promise::get\_return\_object\_on\_allocation\_failure() to the caller, e.g.:

%%% ------- Implementation details of a coroutine ------------------------
\subsection{Implementation details/concepts of a coroutine}
% \begin{lstlisting}[language=C, frame=single, caption={minimum coroutine co_yield example}, label={lst:minimum_coroutine_co_yield_example}]
%   struct Task {
%     struct promise_type {
%       int _val{};
%       Task get_return_object() { return Task{this}; }
%       std::suspend_never initial_suspend() { return {}; }
%       std::suspend_always final_suspend() noexcept { return {}; }
%       std::suspend_always yield_value(int value) { _val = value; return {}; }
%       void unhandled_exception() { }
%       };

%       std::coroutine_handle<promise_type> h{};  // coroutine handle

%       explicit Task(promise_type* p) : h{std::coroutine_handle<promise_type>::from_promise(*p)}{}
%       Task(Task&& rhs) : h{std::exchange(rhs.h, nullptr)} { }
%       ~Task() { if (h) { h.destroy(); } }
% };
% Task Coroutine() {
%     for (int i = 0; i < 5; ++i) {
%       co_yield i;
%     }
% }
% \end{lstlisting}
The following is a minimum coroutine example using co\_await, illustrated in \autoref{lst:minimum_coroutine_co_await_example}.
The Task struct is a the coroutine wrapper holding the coroutine handle and the promise\_type struct defining the promise type and thus, the behavior of the coroutine.
The function Task Coroutine(int num\_steps) is the coroutine function containing a co\_await expression suspending the coroutine for num\_steps times.
And as explained in previous subsection, also see \autoref{lst:coroutine_execution}, when another function, e.g. main(), calls the coroutine, the coroutine frame is allocated on the heap, the promise object is constructed and initial\_suspend() is called.
When the coroutine hits the co\_await expression, it suspends execution and returns control to the caller until it is resumed again.
The coroutine results in the output of "Coroutine at step i" and "Resuming coroutine" for num\_steps times, in this case from 0 to 4, as initial\_suspend() is set to suspend\_never and thus, the coroutine starts executing immediately when called.
If it it set to suspend\_always, the coroutine initially pauses before starting work (lazily computed coroutine) and results in "Resuming coroutine" being printed first followed by "Coroutine at step i"  num\_steps times.
\begin{lstlisting}[language=C, frame=single, caption={minimum coroutine co\_await example}, label={lst:minimum_coroutine_co_await_example}]
  struct Task {
    struct promise_type {
        Task get_return_object() { return Task{this}; }
        std::suspend_always initial_suspend() { return {}; }
        std::suspend_never final_suspend() noexcept { return {}; }
        void unhandled_exception() { }
        void return_void() { }
      };

      std::coroutine_handle<promise_type> h{};  // coroutine handle

      explicit Task(promise_type* p) : h{std::coroutine_handle<promise_type>::from_promise(*p)}{}
      Task(Task&& rhs) : h{std::exchange(rhs.h, nullptr)} { }
      ~Task() { if (h) { h.destroy(); } }
};
Task PrintCoroStep(int num_steps) {
    for (int i = 0; i < num_steps; ++i) {
      std::cout << "Coroutine at step " << i << "\n";
      co_await std::suspend_always{};  // if suspend_never, coro would never pause
    }
    co_return;  // equivalent to omitting this line
}
int main() {
    Task task = PrintCoroStep(5);
    for (int i = 0; i < 5; ++i) {
      std::cout << "Resuming coroutine\n";
      task.h.resume();
    }
}
\end{lstlisting}
In this simple example, trivial awaitables std::suspend\_always and std::suspend\_never, defined in the standard library, are used to control the suspension behavior of the coroutine at the initial and co\_await suspension points.
The implementation of suspend\_always is shown in \autoref{lst:suspend_always} returning false in await\_ready(), indicating that the await expression always suspends and waits for a value (is not ready).
The suspend\_never implementation is analog with the only difference of returning true in await\_ready(), indicating that the await expression never suspends (is always ready).
\begin{lstlisting}[language=C, frame=single, caption={suspend\_always implementation}, label={lst:suspend_always}]
struct suspend_always {
  constexpr bool await_ready() const noexcept{return false;}
  constexpr void await_suspend(std::coroutine_handle <>) const noexcept {}
  constexpr void await_resume() const noexcept {}
};
\end{lstlisting}

For more customization, more complex awaitabletypes can be implemented, requiring to implement these three methods listed in \autoref{lst:awaitable_type}.
\begin{lstlisting}[language=C, frame=single, caption={awaitable type}, label={lst:awaitable_type}]
  bool await_ready();

  // one of:
  void await_suspend(std::coroutine_handle<> h);
  bool await_suspend(std::coroutine_handle<> h);
  std::coroutine_handle<> await_suspend(std::coroutine_handle<> h);

  T await_resume();
\end{lstlisting}

In the $ co\_await expr; $ operator the expression, the awaiter type, is firstly converted to an awaitable.
If the promise\_type type of the current coroutine has a member function await\_transform, then the awaitable is obtained by calling promise.await\_transform(expr), illustrated in \autoref{lst:pseudo_code_which_awaiter_awaitable}.
Otherwise, the awaitable is expr as-is.

\begin{lstlisting}[language=Python, frame=single, caption={Pseudo Code for deciding which awaiter/awaitable is used}, label={lst:pseudo_code_which_awaiter_awaitable}]
func get_awaitable(promise_type& promise, T&& expr){
  if P has member function await_transform:
    return promise.await_transform(expr);
  else
    return expr;
}

func get_awaiter(awaitable){
  if awaitable has member operator co_await:
    return awaitable.operator co_await();
  else if awaitable has non-member operator co_await:
    return operator co_await(awaitable);
  else:
    return awaitable;
}
\end{lstlisting}

Then, the awaiter object is obtained like illustrated in func get\_awaiter in \autoref{lst:pseudo_code_which_awaiter_awaitable}.
If no operator co\_await is defined, the awaitable itself is the awaiter which implicates that a type can be an awaitable and an awaiter type simultaneously.

Then, awaiter.await\_ready() is called , The coroutine is suspended awaiter.await\_suspend(handle) is called, where handle is the coroutine handle representing the current coroutine.
Inside that function, the suspended coroutine state is observable via that handle,
if await\_suspend returns void, control is immediately returned to the caller/resumer of the current coroutine (this coroutine remains suspended), otherwise
if await\_suspend returns bool, the value true returns control to the caller/resumer of the current coroutine the value false resumes the current coroutine.
if await\_suspend returns a coroutine handle for some other coroutine, that handle is resumed (by a call to handle.resume())
Finally, awaiter.await\_resume() is called (whether the coroutine was suspended or not), and its result is the result of the whole co\_await expr expression.

If the coroutine was suspended in the co\_await expression, and is later resumed, the resume point is immediately before the call to awaiter.await\_resume().

Additionally to suspending the coroutine, the co\_yield expression returns a value to the caller and is
equivalent to co\_await promise.yield\_value(expr).
However, to define the type to return, the promise\_type has to implement the yield\_value() function.


Besides the awaiter/awaitable concept explained in the previous paragraphs, there is also the promise type concept.
These are the two main interfaces, defined by the coroutine Type Specification (TS), for customizing the behavior of coroutines and co\_await expressions:
\begin{itemize}
  \item Awaiter / Awaitable: specifies methods that controls the semantics of co\_await expression. When a value is co\_awaited, the awaitable object allows to specify whether to suspend,
   execute some logic after suspensions (for asynchronously completed operations) and/or execute some logic after the coroutine resumes.
  \item Promise Type: specifies methods for customising the behavior of a coroutine, e.g. the behavior of any co\_await or co\_yield expression inside the coroutine body.
\end{itemize}


The promise\_type struct has to be implemented in the coroutine wrapper type, which can be named arbitrarily, e.g. Task in \autoref{lst:minimum_coroutine_co_await_example}.
It has to follow the scheme illustrated in \autoref{lst:promise_type}.
% A coroutine in C++ is an finite state machine (FSM) that can be controlled and customized by the promise_type.
\begin{lstlisting}[language=C, frame=single, caption={Promise Type}, label={lst:promise_type}]
struct promise_type{
  // required methods
  ReturnType get_return_object();
  std::suspend_always initial_suspend();
  std::suspend_always final_suspend() noexcept;
  void unhandled_exception();

  // depending on ReturnType
  void return_void(); // if ReturnType is void
  void return_value(T value); // if ReturnType is T

  // optional methods
  auto await_transform(U&& value); // customize co_await behavior
  auto yield_value(V value); // customize co_yield behavior
}
\end{lstlisting}

The Promise type is determined by the compiler from the return type of the coroutine using std::coroutine\_traits.



The class template coroutine\_handle can be used to refer to a suspended or executing coroutine.

% COROUTINE HANDLE!!
% You may have noticed the use of the coroutine\_handle<P> type that is passed to the await\_suspend() call of a co\_await expression.

% This type represents a non-owning handle to the coroutine frame and can be used to resume execution of the coroutine or to destroy the coroutine frame. It can also be used to get access to the coroutine’s promise object.

% The coroutine_handle type has the following (abbreviated) interface:


CO\_RETURN operator
% https://www.scs.stanford.edu/~dm/blog/c++-coroutines.html

% \begin{lstlisting}[language=C, frame=single, caption={coroutine chat with await\_transform example}, label={lst:coroutine_chat_await_transform_example}]
% // #include <coroutine> #include <iostream> #include <utility>
% struct Chat {
%     struct promise_type {
%         std::string _msgOut{}, _msgIn{};

%         void unhandled_exception()noexcept{};
%         Chat get_return_object() {return Chat{this};}
%         std::suspend_always initial_suspend() { return {}; }
%         std::suspend_always final_suspend() noexcept { return {}; }
%         std::suspend_always yield_value(std::string msg) {
%           _msgOut = std::move(msg); return {};}
%         void return_value(std::string msg) noexcept {
%           _msgOut = std::move(msg); }
%         auto await_transform(std::string) noexcept {
%             struct awaiter {
%                 promise_type& pt;
%                 constexpr bool await_ready() const noexcept {return true;}
%                 void await_suspend(std::coroutine_handle<>)const noexcept{}
%                 std::string await_resume() const noexcept {
%                   return std::move(pt._msgIn); }
%             };
%             return awaiter{*this};
%         }
%     };
%     std::coroutine_handle<promise_type> _hdl;
%     explicit Chat(promise_type* p) : _hdl{
%       std::coroutine_handle<promise_type>::from_promise(*p)}{}
%     Chat(Chat&& rhs) : _hdl{std::exchange(rhs._hdl, nullptr)} {}
%     ~Chat() {if (_hdl) {_hdl.destroy();}}

%     std::string listen() {
%         if(not _hdl.done()) {_hdl.resume();}
%         return std::move(_hdl.promise()._msgOut);}
%     void answer(std::string msg) {
%         _hdl.promise()._msgIn = msg;
%         if(not _hdl.done()) {_hdl.resume();}}
% };

% Chat Fun(){
%     co_yield "Hello\n";
%     std::cout << co_await std::string{};
%     co_return "Here!\n";}
% int main(){
%     Chat chat = Fun();
%     std::cout << chat.listen();
%     chat.answer("Where are you?\n");
%     std::cout << chat.listen();
% }
% \end{lstlisting}


\cite{baker2018understanding}
\cite{baker2018promise}


%%% ------ Comparison to other alternative solutions to hide cache misses ------------------------
\subsection{Comparison to other alternative solutions to hide cache misses}
AMAC, Group Prefetching
coro is better, not performance wise but easier to use, more general


%%% ====== CACHE MISSES =======================
\section{Cache Misses}\label{section:CacheMisses}
\subsection{What are cache misses?}
Cache misses are a fundamental concept in computer architecture, representing instances where requested data is not found in the cache, necessitating a slower access to main memory. They are typically categorized into three main types: compulsory misses, capacity misses, and conflict misses.
 Compulsory misses occur on the first access to a block, as the data has not yet been loaded into the cache regardless of cache design.
 Capacity misses happen when the cache is too small to hold all the data actively used by a program during execution, meaning the working set exceeds the cache size.
 This type of miss is directly related to the cache's capacity and can be reduced by increasing the cache size.
 Conflict misses, also known as interference misses, occur when multiple memory addresses map to the same cache set, leading to evictions of useful data even though the cache is not full.
 These misses are influenced by the cache's associativity; increasing associativity can reduce conflict misses, especially in smaller caches.

The performance of a cache is often measured using metrics such as the cache miss rate, which is the percentage of memory requests that result in a cache miss, calculated as the total number of misses divided by the total number of memory requests over a given time interval.
 The miss rate is inversely related to the hit rate, with the sum of the two equaling 100%.
 The miss rate is a critical indicator for evaluating system performance and can be used to guide optimizations in both hardware and software. For example, in multi-tasking environments, the last-level cache (LLC) miss rate is commonly used to assess an application’s contention characteristics and sensitivity to resource competition.
 However, while the LLC miss rate is effective in distinguishing CPU-bound from memory-bound applications, it is less reliable for predicting the degree of contention or sensitivity in memory-bound workloads.

Research and literature have explored various strategies to mitigate cache misses. Increasing cache capacity can reduce both capacity and conflict misses, although it does not affect compulsory misses.
 Adjusting block size can also impact miss rates; larger blocks may reduce compulsory misses due to spatial locality but can increase conflict misses by reducing the number of sets in a fixed-size cache.
 Techniques such as loop nest optimization and virtual coloring are used in software to minimize conflict misses by ensuring that frequently accessed data does not map to the same cache set.
 Additionally, cache replacement policies like LRU (Least Recently Used) and write strategies such as write-back or write-through are designed to manage data in the cache efficiently, with the goal of minimizing the number of misses and their associated penalties.

The study of cache misses continues to be an active area of research, particularly in the context of modern multi-core and heterogeneous systems where contention and memory access patterns are complex. Performance monitoring units (PMUs) are often used to collect data on cache misses, enabling the development of contention-aware runtime systems and scheduling algorithms.
 Despite the availability of these tools, the challenge remains in accurately predicting the impact of cache misses on overall system performance, especially for memory-intensive applications.




\begin{figure}[h]
  \centering
  \includegraphics[width=0.6\paperwidth]{figures/prefetch_instructions_lifecycle_through_memory_subsystem.png}
  \caption{Prefetch Lifecycle through memory subsystem}
  % \quelle{\cite{ADaSurvey}}
  \label{fig:PrefetchLifecycleThroughMemorySubsystem}
\end{figure}



\subsection{When can they happen?}

\subsection{Why are they relevant in data bases and different index structures}

\subsection{Cache Misses in Data Structures}\label{section:DataStructures}
Chaining vs Open Addressing (Linear Probing)
B+ Tree





%%% ====== COMPUTER ARCHITECTURE =======================
\section{Computer Architecture}\label{section:ComputerArchitecture}
\subsection{Different Computer Architectures, x86-64, amd, apple, mips}

\subsection{Introduction to computer achitecture and storage layout}

\subsection{Different Compilers - Gnu vs Clang}




