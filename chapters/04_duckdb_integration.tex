% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Integration of Coroutines in DuckDB}\label{chapter:DuckDBIntegration}

% reference to CoroBase


\section{DuckDB Overview}\label{section:DuckDBOverview}
% https://dbdb.io/db/duckdb
DuckDB is an open-source column-oriented Relational embeddable analytical DBMS that focuses on supporting analytical query workloads (OLAP).
It is similar to SQLite in that it prioritizes simplicity and ease of integration by eliminating external dependencies for compilation and run-time.
Its columnar-vectorized execution model operates on large bacthes of values simultaneously, reducing the CPU cycles expended per invidivual value.
This architecture design optimizese DuckDB for analytical workloads, and facilitates efficient data movement in embedded deployments.
For providing transactional guarantees (ACID properties), DuckDB employs its custom bulk-optimized multi-version concurrency control (MVCC).
Furthermore, DuckDB supports secondary indexes to accelerate finding a single table entry.

DuckDB implements multiple join strategies, namely hash joins, merge-sort joins, and index-driven joins.
Its query optimizer leverages dynamic programming for join ordering optimization and greedy heuristics for larger join graphs as fallback.
Having a set of rewrite rules to simplify the expression tree, it also flattens any subqueries.
These optimizations produce a refined logical query plan, which the physical optimizer then maps to concrete execution strategies.
For tables exceeding available memory, the system also provides an external hash-join implementation.

As mentioned in previous paragraphs, DuckDB uses a vectorized execution engine avoiding external dependencies and using templates for code generation.
Thus, it does not suport Just-in-Time (JIT) compilation of SQL queries, as these would require large compiler libraries such as LLVM, creating additional transitive dependencies and complicating deployment and integration.
% DuckDB engine supports fixed-length types like integers as native arrays and variable-length values like strings as a native array of pointers into a separate string heap.
% To represent NULL values, a separate bit vector is used only if any appear in the vector.
In particular, this vectorized execution model is a pull-based model that is also known as "vector volcano".
Query execution starts by pulling the first chunk of data from the root node of the physical plan.
A chunk is a horizontal subset of a result set, query intermediate, or base table.
This node will recursively pull chunks from child nodes, eventually arriving at a scan operator that produces chunks by reading from the persistent tables.
The process continues until the chunk arriving at the root is empty, indicating that the query has been completed.

For this work, the focus is on the hash-join implementation of DuckDB, as it is the most relevant join algorithm for large analytical queries.

% DuckDB uses a vectorized processing model that processes batches of columns at a time, which is optimized for CPU cache locality, suitable for SIMD instructions and pipelining,
% and has small intermediates that ideally fit in L1 cache.
% The system contains an extensive library of vector operations that support the relational operators, and this library expands code for all supported data types using C++ code templates.

\section{Understanding the Linear Hashtable in DuckDB}\label{section:UnderstandingLinearHashtableDuckDB}
% Citation test~\parencite{latex}.



\section{Integration of Coroutines in DuckDB}\label{section:IntegrationCoroutinesDuckDB}

DuckDB integration: linear probing hashtabale where if same key it is chained.

% join_hashtable.cpp and join\_hashtable.hpp (vs aggregate hashtable in aggregate\_hashtable.hpp.cpp and base\_aggregate\_hashtable.cpp/.hpp)

Difficulty in understanding the hashtable and implementing coroutines in huge concept of hastable withotu knowing full picture.
has to be done in Join phase of the hastable (which is divided in different datachaunks and each datachunk is handled by a thread wher ea thread cna possibly handle more datachunks).
In this thread coroutines can easily integrated as they are asynchronoulsy called and ...




% \section{} for implementation?



\section{Benchmarking}\label{section:Benchmarking}
which benchmarking used, integrated benchmarkign framework of duckdb and only tpch queries



% \subsection{Results per machine}\label{subsection:ResultsPerMachine}


% \subsection{Results per compiler}\label{subsection:ResultsPerCompiler}


% \subsection{results across machines and compiler}\label{subsection:ResultsAcrossMachinesAndCompiler}


% \subsection{results per query}\label{subsection:ResultsPerQuery}


